# src/tools/youtube_tools.py

from langchain_ollama import ChatOllama
import os
from youtube_search import YoutubeSearch
from langchain_classic.chains.summarize import load_summarize_chain
from langchain_community.document_loaders import YoutubeLoader

# Importamos la definici√≥n de AgentState desde el archivo agent.py
# El '..' indica que subimos un nivel en la estructura de directorios para encontrar el m√≥dulo.
from typing import TypedDict, List
from langchain_core.messages import BaseMessage
from langchain_core.documents import Document

class AgentState(TypedDict):
    topic: str
    video_urls: List[str]
    video_metadata: List[dict]
    summaries: List[str]
    web_research: List[dict]
    wiki_research: List[dict]
    arxiv_research: List[dict]
    github_research: List[dict]
    scholar_research: List[dict]
    hn_research: List[dict]
    so_research: List[dict]
    consolidated_summary: str
    bibliography: List[str]
    pdf_path: str
    report: str
    messages: List[BaseMessage]

# --------------------------------------------------------------------------
# NODO 1: B√öSQUEDA DE V√çDEOS EN YOUTUBE
# --------------------------------------------------------------------------
def search_videos_node(state: AgentState) -> dict:
    """
    Busca v√≠deos en YouTube y extrae sus metadatos (t√≠tulo, autor, URL).

    Args:
        state (AgentState): El estado actual del agente.

    Returns:
        dict: Un diccionario con 'video_urls' y 'video_metadata' inicializado.
    """
    print("\n--- üîé NODO: BUSCANDO V√çDEOS ---")
    topic = state["topic"]
    print(f"Tema de b√∫squeda: {topic}")

    try:
        # Usamos YoutubeSearch para obtener m√°s resultados y metadatos b√°sicos
        max_results = 5
        results = YoutubeSearch(topic, max_results=max_results).to_dict()
        
        video_urls = []
        video_metadata = []

        for res in results:
            video_id = res['id']
            url = f"https://www.youtube.com/watch?v={video_id}"
            video_urls.append(url)
            
            # Guardamos los metadatos que ya tenemos
            video_metadata.append({
                "title": res.get('title', 'T√≠tulo no disponible'),
                "author": res.get('channel', 'Autor no disponible'),
                "url": url
            })

        print(f"‚úÖ Se encontraron {len(video_urls)} v√≠deos con sus metadatos.")
        return {"video_urls": video_urls, "video_metadata": video_metadata}

    except Exception as e:
        print(f"‚ùå Error durante la b√∫squeda de v√≠deos: {e}")
        return {"video_urls": [], "video_metadata": []}


# --------------------------------------------------------------------------
# NODO 2: EXTRACCI√ìN Y RESUMEN DE TRANSCRIPCIONES
# --------------------------------------------------------------------------
def summarize_videos_node(state: AgentState) -> dict:
    """
    Genera res√∫menes para los v√≠deos usando las transcripciones.
    """
    print("\n--- üìù NODO: EXTRAYENDO Y RESUMIENDO V√çDEOS ---")
    video_urls = state["video_urls"]
    video_metadata = state["video_metadata"]
    summaries = []

    if not video_urls:
        print("‚ö†Ô∏è No se encontraron v√≠deos para resumir. Saltando este paso.")
        return {"summaries": []}

    # Aseguramos que las peticiones locales no pasen por un proxy.
    os.environ["NO_PROXY"] = "localhost,127.0.0.1"
    os.environ["no_proxy"] = "localhost,127.0.0.1"

    # Inicializamos el modelo de lenguaje local v√≠a Ollama.
    ollama_base_url = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")
    ollama_model = os.getenv("OLLAMA_MODEL", "qwen2.5:14b")
    
    llm = ChatOllama(
        base_url=ollama_base_url,
        model=ollama_model,
        temperature=0
    )

    summarize_chain = load_summarize_chain(llm, chain_type="map_reduce")

    for i, url in enumerate(video_urls):
        print(f"\nProcesando v√≠deo {i+1}/{len(video_urls)}: {url}")
        metadata = video_metadata[i]
        print(f"  - T√≠tulo: {metadata['title']}")

        try:
            # Cargamos la transcripci√≥n (intentando espa√±ol e ingl√©s)
            loader = YoutubeLoader.from_youtube_url(url, add_video_info=False, language=["es", "en"])
            docs = loader.load()
            
            if not docs:
                raise ValueError("No se pudo obtener la transcripci√≥n.")

            # Resumimos
            summary = summarize_chain.run(docs)
            summaries.append(summary)
            print("  - ‚úÖ Resumen generado desde transcripci√≥n.")

        except Exception as e:
            print(f"  - ‚ö†Ô∏è Error al obtener transcripci√≥n: {e}")
            print(f"  - üîÑ Usando metadatos como fallback...")
            
            # Fallback: Usar t√≠tulo y descripci√≥n si no hay transcripci√≥n
            # Creamos un documento "fake" con la informaci√≥n disponible
            fallback_text = f"T√≠tulo del v√≠deo: {metadata.get('title')}\nCanal: {metadata.get('author')}\n"
            
            # Intentar obtener m√°s detalles con YoutubeSearch si es posible, o usar lo que tenemos
            fallback_doc = Document(page_content=fallback_text)
            
            try:
                # Usamos el LLM para generar un resumen basado en el t√≠tulo/autor (que es mejor que nada)
                # O simplemente reportamos la limitaci√≥n de forma elegante
                prompt = f"Genera un breve p√°rrafo explicando de qu√© trata este v√≠deo bas√°ndote solo en su t√≠tulo: '{metadata.get('title')}'. Menciona que es una fuente audiovisual relevante para el tema {state['topic']}."
                summary = llm.invoke(prompt).content
                summaries.append(summary)
                print("  - ‚úÖ Resumen generado desde metadatos.")
            except Exception as e_inner:
                print(f"  - ‚ùå Error final en fallback: {e_inner}")
                summaries.append(f"V√≠deo titulado '{metadata.get('title')}' por {metadata.get('author')}. No fue posible extraer el contenido detallado debido a restricciones de YouTube.")

    return {"summaries": summaries}