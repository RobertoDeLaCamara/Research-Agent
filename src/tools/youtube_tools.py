# src/tools/youtube_tools.py

from langchain_openai import ChatOpenAI
from langchain.chains.summarize import load_summarize_chain
from langchain_community.document_loaders import YoutubeLoader
from langchain_community.tools import YouTubeSearchTool

# Importamos la definici√≥n de AgentState desde el archivo agent.py
# El '..' indica que subimos un nivel en la estructura de directorios para encontrar el m√≥dulo.
from ..agent import AgentState

# --------------------------------------------------------------------------
# NODO 1: B√öSQUEDA DE V√çDEOS EN YOUTUBE
# --------------------------------------------------------------------------
def search_videos_node(state: AgentState) -> dict:
    """
    Busca v√≠deos en YouTube basados en el tema proporcionado en el estado.

    Este nodo utiliza la herramienta 'YouTubeSearchTool' de LangChain para
    encontrar las 10 URLs de v√≠deo m√°s relevantes para el tema de investigaci√≥n.

    Args:
        state (AgentState): El estado actual del agente, que debe contener el 'topic'.

    Returns:
        dict: Un diccionario con la clave 'video_urls' para actualizar el estado del agente.
    """
    print("\n--- üîé NODO: BUSCANDO V√çDEOS ---")
    topic = state["topic"]
    print(f"Tema de b√∫squeda: {topic}")

    try:
        # Inicializamos la herramienta de b√∫squeda de YouTube.
        # Esta herramienta se encarga de hacer la llamada a la API de YouTube por nosotros.
        tool = YouTubeSearchTool()

        # Ejecutamos la b√∫squeda. Le pedimos expl√≠citamente los 10 resultados m√°s relevantes.
        # La herramienta devuelve una cadena con formato de lista de Python, ej: "['/watch?v=...', '/watch?v=...']"
        search_results_str = tool.run(f"{topic}, top 10 relevant videos")

        # Convertimos la cadena de resultados en una lista real de Python.
        # Es importante usar eval() aqu√≠, ya que la salida de la herramienta est√° dise√±ada para ello.
        video_urls = eval(search_results_str)

        print(f"‚úÖ Se encontraron {len(video_urls)} v√≠deos.")
        return {"video_urls": video_urls}

    except Exception as e:
        print(f"‚ùå Error durante la b√∫squeda de v√≠deos: {e}")
        # Si hay un error, devolvemos una lista vac√≠a para no detener el flujo.
        return {"video_urls": []}


# --------------------------------------------------------------------------
# NODO 2: EXTRACCI√ìN Y RESUMEN DE TRANSCRIPCIONES
# --------------------------------------------------------------------------
def summarize_videos_node(state: AgentState) -> dict:
    """
    Para cada URL de v√≠deo, extrae su transcripci√≥n y genera un resumen ejecutivo.

    Este nodo itera sobre las 'video_urls' del estado. Para cada una, utiliza
    'YoutubeLoader' para obtener la transcripci√≥n y luego un LLM con una cadena
    de resumen para crear un resumen t√©cnico.

    Args:
        state (AgentState): El estado actual del agente, que contiene 'video_urls'.

    Returns:
        dict: Un diccionario con 'summaries' y 'video_metadata' para actualizar el estado.
    """
    print("\n--- üìù NODO: EXTRAYENDO Y RESUMIENDO V√çDEOS ---")
    video_urls = state["video_urls"]
    summaries = []
    video_metadata = []

    if not video_urls:
        print("‚ö†Ô∏è No se encontraron v√≠deos para resumir. Saltando este paso.")
        return {"summaries": [], "video_metadata": []}

    # Inicializamos el modelo de lenguaje que usaremos para resumir.
    # 'gpt-3.5-turbo-16k' es una buena opci√≥n por su gran ventana de contexto.
    llm = ChatOpenAI(temperature=0, model_name="gpt-3.5-turbo-16k")

    # Definimos el prompt (instrucci√≥n) para nuestro resumen.
    # Queremos un resumen t√©cnico y conciso.
    summary_prompt = """
    Escribe un resumen ejecutivo conciso de la siguiente transcripci√≥n de v√≠deo.
    El resumen debe estar dirigido a una audiencia t√©cnica, destacando los puntos clave,
    conceptos principales y conclusiones importantes.

    Transcripci√≥n:
    "{text}"

    RESUMEN EJECUTIVO CONCISO:
    """

    # Cargamos una "cadena de resumen" de LangChain.
    # 'map_reduce' es eficiente para documentos largos como las transcripciones.
    summarize_chain = load_summarize_chain(
        llm,
        chain_type="map_reduce",
        map_prompt=summary_prompt,
        combine_prompt=summary_prompt
    )

    for i, url_suffix in enumerate(video_urls):
        full_url = f"https://www.youtube.com{url_suffix}"
        print(f"\nProcesando v√≠deo {i+1}/{len(video_urls)}: {full_url}")

        try:
            # Usamos el cargador de YouTube de LangChain.
            # 'add_video_info=True' nos da acceso a metadatos como el t√≠tulo y el autor.
            loader = YoutubeLoader.from_youtube_url(full_url, add_video_info=True, language=["es", "en"])
            docs = loader.load()

            # Extraemos los metadatos antes de resumir
            metadata = docs[0].metadata
            title = metadata.get("title", "T√≠tulo no disponible")
            author = metadata.get("author", "Autor no disponible")
            print(f"  - T√≠tulo: {title}")

            # Ejecutamos la cadena de resumen sobre la transcripci√≥n.
            summary = summarize_chain.run(docs)
            summaries.append(summary)

            video_metadata.append({
                "title": title,
                "author": author,
                "url": full_url
            })
            print("  - ‚úÖ Resumen generado.")

        except Exception as e:
            print(f"  - ‚ö†Ô∏è No se pudo procesar el v√≠deo {full_url}: {e}")
            # Si hay un error (ej. sin transcripci√≥n), a√±adimos un marcador
            # para que el informe final refleje que este v√≠deo no se pudo procesar.
            summaries.append("No fue posible generar un resumen para este v√≠deo (puede que no tenga transcripci√≥n).")
            video_metadata.append({
                "title": f"V√≠deo no procesado en {full_url}",
                "author": "Desconocido",
                "url": full_url
            })

    return {"summaries": summaries, "video_metadata": video_metadata}