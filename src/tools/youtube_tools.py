# src/tools/youtube_tools.py

from langchain_ollama import ChatOllama
import os
from youtube_search import YoutubeSearch
from langchain_classic.chains.summarize import load_summarize_chain
from langchain_community.document_loaders import YoutubeLoader

# Importamos la definici√≥n de AgentState desde el archivo agent.py
# El '..' indica que subimos un nivel en la estructura de directorios para encontrar el m√≥dulo.
from typing import TypedDict, List
from langchain_core.messages import BaseMessage

class AgentState(TypedDict):
    topic: str
    video_urls: List[str]
    video_metadata: List[dict]
    summaries: List[str]
    web_research: List[dict]
    wiki_research: List[dict]
    arxiv_research: List[dict]
    consolidated_summary: str
    report: str
    messages: List[BaseMessage]

# --------------------------------------------------------------------------
# NODO 1: B√öSQUEDA DE V√çDEOS EN YOUTUBE
# --------------------------------------------------------------------------
def search_videos_node(state: AgentState) -> dict:
    """
    Busca v√≠deos en YouTube y extrae sus metadatos (t√≠tulo, autor, URL).

    Args:
        state (AgentState): El estado actual del agente.

    Returns:
        dict: Un diccionario con 'video_urls' y 'video_metadata' inicializado.
    """
    print("\n--- üîé NODO: BUSCANDO V√çDEOS ---")
    topic = state["topic"]
    print(f"Tema de b√∫squeda: {topic}")

    try:
        # Usamos YoutubeSearch para obtener m√°s resultados y metadatos b√°sicos
        max_results = 5
        results = YoutubeSearch(topic, max_results=max_results).to_dict()
        
        video_urls = []
        video_metadata = []

        for res in results:
            video_id = res['id']
            url = f"https://www.youtube.com/watch?v={video_id}"
            video_urls.append(url)
            
            # Guardamos los metadatos que ya tenemos
            video_metadata.append({
                "title": res.get('title', 'T√≠tulo no disponible'),
                "author": res.get('channel', 'Autor no disponible'),
                "url": url
            })

        print(f"‚úÖ Se encontraron {len(video_urls)} v√≠deos con sus metadatos.")
        return {"video_urls": video_urls, "video_metadata": video_metadata}

    except Exception as e:
        print(f"‚ùå Error durante la b√∫squeda de v√≠deos: {e}")
        return {"video_urls": [], "video_metadata": []}


# --------------------------------------------------------------------------
# NODO 2: EXTRACCI√ìN Y RESUMEN DE TRANSCRIPCIONES
# --------------------------------------------------------------------------
def summarize_videos_node(state: AgentState) -> dict:
    """
    Genera res√∫menes para los v√≠deos usando las transcripciones.
    """
    print("\n--- üìù NODO: EXTRAYENDO Y RESUMIENDO V√çDEOS ---")
    video_urls = state["video_urls"]
    video_metadata = state["video_metadata"]
    summaries = []

    if not video_urls:
        print("‚ö†Ô∏è No se encontraron v√≠deos para resumir. Saltando este paso.")
        return {"summaries": []}

    # Aseguramos que las peticiones locales no pasen por un proxy.
    os.environ["NO_PROXY"] = "localhost,127.0.0.1"
    os.environ["no_proxy"] = "localhost,127.0.0.1"

    # Inicializamos el modelo de lenguaje local v√≠a Ollama.
    ollama_base_url = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")
    ollama_model = os.getenv("OLLAMA_MODEL", "qwen2.5:14b")
    
    llm = ChatOllama(
        base_url=ollama_base_url,
        model=ollama_model,
        temperature=0
    )

    summarize_chain = load_summarize_chain(llm, chain_type="map_reduce")

    for i, url in enumerate(video_urls):
        print(f"\nProcesando v√≠deo {i+1}/{len(video_urls)}: {url}")
        metadata = video_metadata[i]
        print(f"  - T√≠tulo: {metadata['title']}")

        try:
            # Cargamos la transcripci√≥n (intentando espa√±ol e ingl√©s)
            loader = YoutubeLoader.from_youtube_url(url, add_video_info=False, language=["es", "en"])
            docs = loader.load()

            # Resumimos
            summary = summarize_chain.run(docs)
            summaries.append(summary)
            print("  - ‚úÖ Resumen generado.")

        except Exception as e:
            print(f"  - ‚ö†Ô∏è Error al procesar {url}: {e}")
            summaries.append("No fue posible generar un resumen para este v√≠deo.")

    return {"summaries": summaries}