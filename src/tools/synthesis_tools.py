import os
from typing import List, TypedDict
from langchain_ollama import ChatOllama
from langchain_core.messages import BaseMessage, HumanMessage

class AgentState(TypedDict):
    topic: str
    video_urls: List[str]
    video_metadata: List[dict]
    summaries: List[str]
    web_research: List[dict]
    wiki_research: List[dict]
    arxiv_research: List[dict]
    github_research: List[dict]
    scholar_research: List[dict]
    hn_research: List[dict]
    so_research: List[dict]
    consolidated_summary: str
    bibliography: List[str]
    pdf_path: str
    report: str
    messages: List[BaseMessage]

def consolidate_research_node(state: AgentState) -> dict:
    """
    Sintetiza toda la informaci√≥n recolectada en un informe consolidado √∫nico.
    """
    print("\n--- üß† NODO: SINTETIZANDO INVESTIGACI√ìN ---")
    
    topic = state["topic"]
    wiki = state.get("wiki_research", [])
    web = state.get("web_research", [])
    arxiv = state.get("arxiv_research", [])
    scholar = state.get("scholar_research", [])
    github = state.get("github_research", [])
    hn = state.get("hn_research", [])
    so = state.get("so_research", [])
    yt_summaries = state.get("summaries", [])
    
    # Construcci√≥n del contexto para el LLM
    context = f"TEMA DE INVESTIGACI√ìN: {topic}\n\n"
    
    if wiki:
        context += "--- INFORMACI√ìN DE WIKIPEDIA ---\n"
        for item in wiki:
            context += f"T√≠tulo: {item.get('title')}\nContenido: {item.get('summary')}\n\n"
            
    if web:
        context += "--- RESULTADOS DE B√öSQUEDA WEB ---\n"
        for item in web:
            context += f"Contenido: {item.get('content', item.get('snippet', ''))}\n\n"
            
    if arxiv:
        context += "--- ART√çCULOS CIENT√çFICOS (ARXIV) ---\n"
        for item in arxiv:
            context += f"T√≠tulo: {item.get('title')}\nResumen: {item.get('summary')}\nURL: {item.get('url')}\n\n"
            
    if scholar:
        context += "--- ART√çCULOS ACAD√âMICOS DESTACADOS (SEMANTIC SCHOLAR) ---\n"
        for item in scholar:
            context += f"T√≠tulo: {item.get('title')} ({item.get('year', 'N/A')})\n"
            context += f"Autores: {item.get('authors')}\n"
            context += f"Resumen: {item.get('content')}\n"
            context += f"URL: {item.get('url')}\n\n"
            
    if github:
        context += "--- REPOSITORIOS Y C√ìDIGO (GITHUB) ---\n"
        for item in github:
            context += f"Repo: {item.get('name')}\nDescripci√≥n: {item.get('description')}\nEstrellas: {item.get('stars')}\nURL: {item.get('url')}\n\n"
            
    if hn:
        context += "--- DISCUSIONES EN HACKER NEWS ---\n"
        for item in hn:
            context += f"T√≠tulo: {item.get('title')}\nAutor: {item.get('author')}\nPuntos: {item.get('points')}\nURL: {item.get('url')}\n\n"
            
    if so:
        context += "--- PREGUNTAS T√âCNICAS (STACK OVERFLOW) ---\n"
        for item in so:
            context += f"T√≠tulo: {item.get('title')}\nScore: {item.get('score')}\nResuelta: {item.get('is_answered')}\nURL: {item.get('url')}\n\n"
            
    if yt_summaries:
        context += "--- RES√öMENES DE YOUTUBE ---\n"
        for i, summary in enumerate(yt_summaries):
            context += f"Video {i+1}: {summary}\n\n"

    prompt = f"""
Eres un experto analista de investigaci√≥n. Tu tarea es crear un INFORME CONSOLIDADO Y PROFESIONAL basado en la informaci√≥n proporcionada arriba.
El informe debe ser t√©cnico, estructurado y f√°cil de leer.

Instrucciones:
1. Divide el informe en secciones l√≥gicas (Introducci√≥n, Tendencias Clave, Tecnolog√≠as Emergentes, Implementaciones de C√≥digo, Conclusiones).
2. Integra la informaci√≥n de todas las fuentes (Wikipedia, Web, arXiv, Semantic Scholar, GitHub, Hacker News, Stack Overflow y YouTube) de manera fluida.
3. El lenguaje debe ser profesional y objetivo.
4. MANDATORIO: Cada vez que menciones un repositorio de GitHub, un art√≠culo de arXiv, de Semantic Scholar, una discusi√≥n de Hacker News o una pregunta de Stack Overflow, DEBES incluir su URL correspondiente (ej. usando formato Markdown [Nombre](URL) o simplemente la URL entre par√©ntesis). No omitas ninguna URL proporcionada en el contexto.
5. IMPORTANTE: Responde √öNICAMENTE con el cuerpo del informe en formato Markdown.

INFORMACI√ìN PARA SINTETIZAR:
{context}
    """

    # Inicializaci√≥n del LLM
    ollama_base_url = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")
    ollama_model = os.getenv("OLLAMA_MODEL", "qwen2.5:14b")
    
    llm = ChatOllama(
        base_url=ollama_base_url,
        model=ollama_model,
        temperature=0.3
    )

    try:
        print("Generando s√≠ntesis consolidada...")
        response = llm.invoke([HumanMessage(content=prompt)])
        consolidated_text = response.content
        print("‚úÖ S√≠ntesis completada.")
        return {"consolidated_summary": consolidated_text}
    except Exception as e:
        print(f"‚ùå Error durante la s√≠ntesis: {e}")
        return {"consolidated_summary": "No fue posible generar la s√≠ntesis consolidada."}
